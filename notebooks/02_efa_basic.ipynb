{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2da42ac7",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8bbc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# EFA modules\n",
    "from soc_opros_loader import SocOprosLoader\n",
    "from efa_analyzer import EFAAnalyzer, FactorSolution\n",
    "from factor_validator import FactorValidator\n",
    "from efa_error_handling import get_warning_manager, configure_warnings\n",
    "\n",
    "# Configure warnings\n",
    "configure_warnings(show_warnings=True, level=\"WARNING\")\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='efa_analyzer')\n",
    "\n",
    "print(\"âœ“ Modules imported successfully\")\n",
    "print(\"âœ“ EFA environment ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e701a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load soc opros survey data\n",
    "try:\n",
    "    loader = SocOprosLoader()\n",
    "    \n",
    "    # Try to load real data first\n",
    "    print(\"Attempting to load soc opros data from Google Sheets...\")\n",
    "    data = loader.load_data()\n",
    "    responses_matrix = loader.get_responses_matrix()\n",
    "    \n",
    "    print(f\"âœ“ Real data loaded successfully\")\n",
    "    print(f\"Data shape: {responses_matrix.shape} (statements Ã— respondents)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not load real data: {e}\")\n",
    "    print(\"Using mock data for demonstration...\")\n",
    "    \n",
    "    # Create mock data for demonstration\n",
    "    from efa_integration_test import create_mock_soc_opros_data\n",
    "    responses_matrix = create_mock_soc_opros_data()\n",
    "    print(f\"âœ“ Mock data created: {responses_matrix.shape} (statements Ã— respondents)\")\n",
    "\n",
    "# For EFA, we need observations Ã— variables format\n",
    "efa_data = responses_matrix.T  # Transpose to get respondents Ã— statements\n",
    "print(f\"âœ“ EFA data prepared: {efa_data.shape} (observations Ã— variables)\")\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\nData Overview:\")\n",
    "print(f\"- Number of respondents (observations): {efa_data.shape[0]}\")\n",
    "print(f\"- Number of statements (variables): {efa_data.shape[1]}\")\n",
    "print(f\"- Missing data: {efa_data.isnull().sum().sum()} values ({(efa_data.isnull().sum().sum()/efa_data.size)*100:.1f}%)\")\n",
    "print(f\"- Response range: {efa_data.min().min():.0f} to {efa_data.max().max():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89c2d4d",
   "metadata": {},
   "source": [
    "## 2. Data Validation and Initial Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c4a282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize EFA analyzer and validator\n",
    "efa_analyzer = EFAAnalyzer(\n",
    "    n_factors=None,  # Auto-determine using eigenvalue > 1.0 criterion\n",
    "    extraction_method='principal',\n",
    "    rotation_method='oblimin'  # Default oblimin rotation\n",
    ")\n",
    "\n",
    "validator = FactorValidator()\n",
    "\n",
    "print(\"âœ“ EFA Analyzer initialized:\")\n",
    "print(f\"  - Extraction method: {efa_analyzer.extraction_method}\")\n",
    "print(f\"  - Rotation method: {efa_analyzer.rotation_method}\")\n",
    "print(f\"  - Factor count: {'Auto-determine' if efa_analyzer.n_factors is None else efa_analyzer.n_factors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b519a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform data validation\n",
    "print(\"Data Validation Results:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Basic data validation\n",
    "validation_results = efa_analyzer.validate_data(efa_data)\n",
    "\n",
    "print(f\"âœ“ Data validity: {'VALID' if validation_results.is_valid else 'INVALID'}\")\n",
    "\n",
    "if validation_results.warnings:\n",
    "    print(\"\\nWarnings:\")\n",
    "    for i, warning in enumerate(validation_results.warnings, 1):\n",
    "        print(f\"  {i}. {warning}\")\n",
    "        \n",
    "if validation_results.errors:\n",
    "    print(\"\\nErrors:\")\n",
    "    for i, error in enumerate(validation_results.errors, 1):\n",
    "        print(f\"  {i}. {error}\")\n",
    "\n",
    "# Data adequacy assessment\n",
    "adequacy_results = validator.check_data_adequacy(efa_data)\n",
    "\n",
    "print(f\"\\nâœ“ Sample adequacy: {'ADEQUATE' if adequacy_results.is_adequate else 'INADEQUATE'}\")\n",
    "print(f\"  - Sample size: {adequacy_results.sample_size}\")\n",
    "print(f\"  - Variables: {adequacy_results.n_variables}\")\n",
    "print(f\"  - Ratio: {adequacy_results.ratio:.2f} (recommended: â‰¥5.0)\")\n",
    "\n",
    "if adequacy_results.recommendations:\n",
    "    print(\"\\nRecommendations:\")\n",
    "    for rec in adequacy_results.recommendations:\n",
    "        print(f\"  â€¢ {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b52ad3",
   "metadata": {},
   "source": [
    "## 2.1. Statistical Validation Tests\n",
    "\n",
    "### KMO (Kaiser-Meyer-Olkin) Test\n",
    "Measures sampling adequacy - should be â‰¥ 0.6 for factor analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca57f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMO (Kaiser-Meyer-Olkin) Test\n",
    "print(\"KMO Measure of Sampling Adequacy:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    kmo_results = validator.calculate_kmo(efa_data)\n",
    "    \n",
    "    print(f\"Overall KMO: {kmo_results['overall_kmo']:.3f}\")\n",
    "    print(f\"Interpretation: {kmo_results['interpretation']}\")\n",
    "    print(f\"Threshold: â‰¥ {kmo_results['threshold']}\")\n",
    "    print(f\"Test result: {'âœ“ PASS' if kmo_results['is_adequate'] else 'âœ— FAIL'}\")\n",
    "    \n",
    "    # Show problematic variables\n",
    "    individual_kmo = kmo_results['individual_kmo']\n",
    "    low_kmo_vars = {var: kmo for var, kmo in individual_kmo.items() if kmo < 0.5}\n",
    "    \n",
    "    if low_kmo_vars:\n",
    "        print(f\"\\nVariables with low KMO (< 0.5):\")\n",
    "        for var, kmo in sorted(low_kmo_vars.items(), key=lambda x: x[1])[:5]:\n",
    "            print(f\"  {var}: {kmo:.3f}\")\n",
    "    else:\n",
    "        print(f\"\\nâœ“ All variables have adequate individual KMO values\")\n",
    "    \n",
    "    if kmo_results['recommendations']:\n",
    "        print(f\"\\nRecommendations:\")\n",
    "        for rec in kmo_results['recommendations'][:3]:\n",
    "            print(f\"  â€¢ {rec}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"KMO calculation failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6edd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bartlett's Test of Sphericity\n",
    "print(\"Bartlett's Test of Sphericity:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    bartlett_results = validator.calculate_bartlett_test(efa_data)\n",
    "    \n",
    "    print(f\"Chi-square statistic: {bartlett_results['statistic']:.3f}\")\n",
    "    print(f\"Degrees of freedom: {bartlett_results['degrees_of_freedom']}\")\n",
    "    print(f\"P-value: {bartlett_results['p_value']:.6f}\")\n",
    "    print(f\"Significance level: Î± = {bartlett_results['alpha']}\")\n",
    "    print(f\"Test result: {'âœ“ PASS' if bartlett_results['is_significant'] else 'âœ— FAIL'}\")\n",
    "    print(f\"Interpretation: {bartlett_results['interpretation']}\")\n",
    "    \n",
    "    if bartlett_results['recommendations']:\n",
    "        print(f\"\\nRecommendations:\")\n",
    "        for rec in bartlett_results['recommendations'][:2]:\n",
    "            print(f\"  â€¢ {rec}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Bartlett's test failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dd0c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Sample Size Assessment\n",
    "print(\"Enhanced Sample Size Assessment:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    adequacy_results = validator.check_enhanced_sample_adequacy(efa_data)\n",
    "    \n",
    "    print(f\"Overall Assessment: {adequacy_results['overall_adequacy']}\")\n",
    "    print(f\"Sample Size: {adequacy_results['sample_size']} observations\")\n",
    "    print(f\"Variables: {adequacy_results['n_variables']}\")\n",
    "    print(f\"Ratio: {adequacy_results['ratio']:.1f}:1 (obs:vars)\")\n",
    "    \n",
    "    print(f\"\\nDetailed Assessment:\")\n",
    "    for assessment in adequacy_results['assessments']:\n",
    "        print(f\"  â€¢ {assessment}\")\n",
    "    \n",
    "    if adequacy_results['recommendations']:\n",
    "        print(f\"\\nRecommendations:\")\n",
    "        for rec in adequacy_results['recommendations'][:3]:\n",
    "            print(f\"  â€¢ {rec}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Sample adequacy check failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf7f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix Quality Check\n",
    "print(\"Correlation Matrix Quality Assessment:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    correlation_matrix = efa_analyzer.calculate_correlation_matrix(efa_data, method='pearson')\n",
    "    singularity_results = validator.check_correlation_singularity(correlation_matrix)\n",
    "    \n",
    "    print(f\"Matrix Condition: {singularity_results['severity']}\")\n",
    "    print(f\"Determinant: {singularity_results['determinant']:.2e}\")\n",
    "    print(f\"Condition Number: {singularity_results['condition_number']:.2e}\")\n",
    "    \n",
    "    print(f\"Singular: {'Yes' if singularity_results['is_singular'] else 'No'}\")\n",
    "    print(f\"Near-singular: {'Yes' if singularity_results['is_near_singular'] else 'No'}\")\n",
    "    \n",
    "    if singularity_results['perfect_correlations']:\n",
    "        print(f\"\\nPerfect correlations found ({len(singularity_results['perfect_correlations'])}):\")\n",
    "        for var1, var2, corr in singularity_results['perfect_correlations'][:3]:\n",
    "            print(f\"  â€¢ {var1} â†” {var2}: r = {corr:.3f}\")\n",
    "    \n",
    "    if singularity_results['high_correlations']:\n",
    "        print(f\"\\nHigh correlations found ({len(singularity_results['high_correlations'])}):\")\n",
    "        for var1, var2, corr in singularity_results['high_correlations'][:3]:\n",
    "            print(f\"  â€¢ {var1} â†” {var2}: r = {corr:.3f}\")\n",
    "    \n",
    "    print(f\"\\nInterpretation: {singularity_results['interpretation']}\")\n",
    "    \n",
    "    if singularity_results['recommendations']:\n",
    "        print(f\"Recommendations:\")\n",
    "        for rec in singularity_results['recommendations'][:3]:\n",
    "            print(f\"  â€¢ {rec}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Correlation matrix check failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03108299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Summary\n",
    "print(\"STATISTICAL VALIDATION SUMMARY:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "validation_passed = 0\n",
    "total_tests = 4\n",
    "\n",
    "# Collect all validation results\n",
    "try:\n",
    "    kmo_pass = kmo_results['is_adequate']\n",
    "    bartlett_pass = bartlett_results['is_significant'] \n",
    "    adequacy_pass = adequacy_results['overall_adequacy'] in ['Adequate', 'Good', 'Excellent']\n",
    "    matrix_pass = not (singularity_results['is_singular'] or singularity_results['is_near_singular'])\n",
    "    \n",
    "    print(f\"1. KMO Test: {'âœ“ PASS' if kmo_pass else 'âœ— FAIL'} (KMO = {kmo_results['overall_kmo']:.3f})\")\n",
    "    print(f\"2. Bartlett's Test: {'âœ“ PASS' if bartlett_pass else 'âœ— FAIL'} (p = {bartlett_results['p_value']:.4f})\")\n",
    "    print(f\"3. Sample Adequacy: {'âœ“ PASS' if adequacy_pass else 'âœ— FAIL'} ({adequacy_results['overall_adequacy']})\")\n",
    "    print(f\"4. Matrix Quality: {'âœ“ PASS' if matrix_pass else 'âœ— FAIL'} ({singularity_results['severity']})\")\n",
    "    \n",
    "    validation_passed = sum([kmo_pass, bartlett_pass, adequacy_pass, matrix_pass])\n",
    "    \n",
    "    print(f\"\\nOverall Validation: {validation_passed}/{total_tests} tests passed\")\n",
    "    \n",
    "    if validation_passed >= 3:\n",
    "        print(\"ðŸŽ¯ VALIDATION RESULT: GOOD - Factor analysis can proceed\")\n",
    "        proceed_recommendation = \"Proceed with factor analysis\"\n",
    "    elif validation_passed >= 2:\n",
    "        print(\"âš ï¸  VALIDATION RESULT: MARGINAL - Proceed with caution\")\n",
    "        proceed_recommendation = \"Factor analysis possible but interpret results carefully\"\n",
    "    else:\n",
    "        print(\"âŒ VALIDATION RESULT: POOR - Factor analysis not recommended\")\n",
    "        proceed_recommendation = \"Improve data quality before proceeding\"\n",
    "    \n",
    "    print(f\"Recommendation: {proceed_recommendation}\")\n",
    "    \n",
    "except:\n",
    "    print(\"Could not generate validation summary - check individual test results above\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a93c07",
   "metadata": {},
   "source": [
    "## 3. Correlation Matrix Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47824460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix using Pearson correlations\n",
    "print(\"Calculating Correlation Matrix:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "correlation_matrix = efa_analyzer.calculate_correlation_matrix(efa_data, method='pearson')\n",
    "\n",
    "print(f\"âœ“ Correlation matrix calculated: {correlation_matrix.shape} (variables Ã— variables)\")\n",
    "print(f\"  - Method: Pearson correlations with pairwise deletion\")\n",
    "print(f\"  - Range: {correlation_matrix.min().min():.3f} to {correlation_matrix.max().max():.3f}\")\n",
    "\n",
    "# Display correlation matrix summary\n",
    "print(\"\\nCorrelation Matrix Summary:\")\n",
    "mask = ~np.eye(correlation_matrix.shape[0], dtype=bool)  # Exclude diagonal\n",
    "off_diag_corrs = correlation_matrix.values[mask]\n",
    "\n",
    "print(f\"  - Mean absolute correlation: {np.abs(off_diag_corrs).mean():.3f}\")\n",
    "print(f\"  - Max absolute correlation: {np.abs(off_diag_corrs).max():.3f}\")\n",
    "print(f\"  - Correlations > 0.3: {(np.abs(off_diag_corrs) > 0.3).sum()} ({(np.abs(off_diag_corrs) > 0.3).mean()*100:.1f}%)\")\n",
    "print(f\"  - Correlations > 0.7: {(np.abs(off_diag_corrs) > 0.7).sum()} ({(np.abs(off_diag_corrs) > 0.7).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa222c4",
   "metadata": {},
   "source": [
    "## 4. Factor Analysis Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e712ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform complete factor analysis\n",
    "print(\"Performing Factor Analysis:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    factor_solution = efa_analyzer.fit(efa_data)\n",
    "    \n",
    "    print(f\"âœ“ Factor analysis completed successfully\")\n",
    "    print(f\"  - Extraction method: {factor_solution.extraction_method}\")\n",
    "    print(f\"  - Rotation method: {factor_solution.rotation_method}\")\n",
    "    print(f\"  - Number of factors extracted: {factor_solution.n_factors}\")\n",
    "    print(f\"  - Total variance explained: {factor_solution.variance_explained['total_variance_explained']*100:.1f}%\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Factor analysis failed: {str(e)}\")\n",
    "    factor_solution = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8429cfc7",
   "metadata": {},
   "source": [
    "## 5. Results Analysis and Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9050c72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if factor_solution is not None:\n",
    "    print(\"Factor Analysis Results:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Display eigenvalues and variance explained\n",
    "    print(\"\\nEigenvalues and Variance Explained:\")\n",
    "    for i, (eigenval, prop_var, cum_var) in enumerate(zip(\n",
    "        factor_solution.variance_explained['eigenvalues'],\n",
    "        factor_solution.variance_explained['proportion_variance'],\n",
    "        factor_solution.variance_explained['cumulative_variance']\n",
    "    )):\n",
    "        print(f\"  Factor {i+1}: Î»={eigenval:.3f}, Prop.Var={prop_var*100:.1f}%, Cum.Var={cum_var*100:.1f}%\")\n",
    "    \n",
    "    # Display factor loadings\n",
    "    print(\"\\nFactor Loadings Matrix (first 10 variables):\")\n",
    "    display_loadings = factor_solution.loadings.head(10).round(3)\n",
    "    print(display_loadings.to_string())\n",
    "    \n",
    "    # Highlight significant loadings (>0.4)\n",
    "    print(\"\\nSignificant Factor Loadings (|loading| > 0.4):\")\n",
    "    for factor in factor_solution.loadings.columns:\n",
    "        significant = factor_solution.loadings[factor][np.abs(factor_solution.loadings[factor]) > 0.4]\n",
    "        if len(significant) > 0:\n",
    "            print(f\"\\n{factor}:\")\n",
    "            for var, loading in significant.sort_values(key=abs, ascending=False).items():\n",
    "                print(f\"  {var}: {loading:.3f}\")\n",
    "        else:\n",
    "            print(f\"\\n{factor}: No significant loadings found\")\n",
    "    \n",
    "    # Display communalities\n",
    "    print(\"\\nCommunalities (first 10 variables):\")\n",
    "    display_communalities = factor_solution.communalities.head(10).round(3)\n",
    "    for var, comm in display_communalities.items():\n",
    "        print(f\"  {var}: {comm:.3f}\")\n",
    "    \n",
    "    print(f\"\\nCommunalities Summary:\")\n",
    "    print(f\"  - Mean: {factor_solution.communalities.mean():.3f}\")\n",
    "    print(f\"  - Range: {factor_solution.communalities.min():.3f} to {factor_solution.communalities.max():.3f}\")\n",
    "    print(f\"  - Variables with comm. > 0.5: {(factor_solution.communalities > 0.5).sum()}/{len(factor_solution.communalities)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc24ac2b",
   "metadata": {},
   "source": [
    "## 6. Factor Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d902c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if factor_solution is not None:\n",
    "    print(\"Factor Interpretation:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    try:\n",
    "        interpretation = efa_analyzer.get_factor_interpretation(factor_solution, loading_threshold=0.4)\n",
    "        \n",
    "        # Overall structure quality\n",
    "        structure = interpretation['structure_summary']\n",
    "        print(f\"Simple Structure Quality: {structure['simple_structure_quality']}\")\n",
    "        print(f\"Variables assigned to factors: {structure['assigned_variables']}/{structure['total_variables']}\")\n",
    "        print(f\"Unassigned variables: {structure['unassigned_variables']}\")\n",
    "        \n",
    "        # Factor-by-factor interpretation\n",
    "        for factor_name, factor_info in interpretation['factor_interpretations'].items():\n",
    "            print(f\"\\n{factor_name}:\")\n",
    "            print(f\"  - Interpretation quality: {factor_info['interpretation_quality']}\")\n",
    "            print(f\"  - Variables with significant loadings: {factor_info['n_significant']}\")\n",
    "            print(f\"  - Maximum loading: {factor_info['max_loading']:.3f}\")\n",
    "            \n",
    "            if factor_info['high_loading_variables']:\n",
    "                print(\"  - High loading variables:\")\n",
    "                for var, loading in list(factor_info['high_loading_variables'].items())[:5]:  # Top 5\n",
    "                    print(f\"    â€¢ {var}: {loading:.3f}\")\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"Could not generate interpretation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a778170",
   "metadata": {},
   "source": [
    "## 7. Factor Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943c275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if factor_solution is not None and factor_solution.factor_scores is not None:\n",
    "    print(\"Factor Scores Summary:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    scores = factor_solution.factor_scores\n",
    "    \n",
    "    print(f\"Factor scores calculated for {len(scores)} observations\")\n",
    "    print(f\"Method: Regression method (precise estimation)\")\n",
    "    \n",
    "    print(\"\\nFactor Score Statistics:\")\n",
    "    for factor in scores.columns:\n",
    "        mean_score = scores[factor].mean()\n",
    "        std_score = scores[factor].std()\n",
    "        print(f\"  {factor}: M={mean_score:.3f}, SD={std_score:.3f}\")\n",
    "    \n",
    "    # Display first few factor scores\n",
    "    print(\"\\nFirst 5 Respondents' Factor Scores:\")\n",
    "    print(scores.head().round(3).to_string())\n",
    "    \n",
    "    # Factor score correlations (should be low for oblique rotation)\n",
    "    print(\"\\nFactor Score Correlations:\")\n",
    "    factor_corrs = scores.corr().round(3)\n",
    "    print(factor_corrs.to_string())\n",
    "else:\n",
    "    print(\"Factor scores not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a8234a",
   "metadata": {},
   "source": [
    "## 8. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9efc989",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Basic EFA Analysis Summary:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if factor_solution is not None:\n",
    "    success_criteria = {\n",
    "        'factors_extracted': factor_solution.n_factors,\n",
    "        'variance_explained': factor_solution.variance_explained['total_variance_explained'] * 100,\n",
    "        'target_variance': 60.0,  # From success criteria SC-001\n",
    "        'target_factors': (3, 8),  # From success criteria SC-001\n",
    "        'factor_range_ok': 3 <= factor_solution.n_factors <= 8,\n",
    "        'variance_ok': factor_solution.variance_explained['total_variance_explained'] >= 0.60\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ“ Number of factors: {success_criteria['factors_extracted']} (target: {success_criteria['target_factors'][0]}-{success_criteria['target_factors'][1]})\")\n",
    "    print(f\"âœ“ Variance explained: {success_criteria['variance_explained']:.1f}% (target: â‰¥{success_criteria['target_variance']}%)\")\n",
    "    print(f\"âœ“ Factor count within range: {'YES' if success_criteria['factor_range_ok'] else 'NO'}\")\n",
    "    print(f\"âœ“ Variance target met: {'YES' if success_criteria['variance_ok'] else 'NO'}\")\n",
    "    \n",
    "    overall_success = success_criteria['factor_range_ok'] and success_criteria['variance_ok']\n",
    "    print(f\"\\nðŸŽ¯ MVP Success Criteria: {'PASSED âœ“' if overall_success else 'PARTIAL âš ï¸'}\")\n",
    "    \n",
    "    if overall_success:\n",
    "        print(\"\\nðŸŽ‰ Basic Factor Discovery (US1) completed successfully!\")\n",
    "        print(\"Ready to proceed to User Story 2: Statistical Validation\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ Some success criteria not met - review data quality and sample size\")\n",
    "else:\n",
    "    print(\"âŒ Factor analysis failed - check data quality and dependencies\")\n",
    "\n",
    "# Show any accumulated warnings\n",
    "warning_mgr = get_warning_manager()\n",
    "summary = warning_mgr.get_summary()\n",
    "if summary['total'] > 0:\n",
    "    print(f\"\\nWarnings generated: {summary['total']}\")\n",
    "    print(f\"By level: {summary['by_level']}\")\n",
    "\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"1. Install scipy and factor-analyzer for full functionality\")\n",
    "print(\"2. Run statistical validation (User Story 2)\")\n",
    "print(\"3. Create visualizations (User Story 3)\")\n",
    "print(\"4. Apply to real soc opros survey data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Insight Digger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
