{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2da42ac7",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e8bbc88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:20:12.264979Z",
     "iopub.status.busy": "2025-11-24T21:20:12.264979Z",
     "iopub.status.idle": "2025-11-24T21:20:12.962317Z",
     "shell.execute_reply": "2025-11-24T21:20:12.962317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Modules imported successfully\n",
      "‚úì EFA environment ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\Insight Digger\\notebooks\\../src\\efa_analyzer.py:23: UserWarning: SciPy not available - some statistical functions will be limited\n",
      "  warnings.warn(\"SciPy not available - some statistical functions will be limited\")\n",
      "C:\\workspace\\Insight Digger\\notebooks\\../src\\efa_analyzer.py:34: UserWarning: factor_analyzer not available - installing dependencies required\n",
      "  warnings.warn(\"factor_analyzer not available - installing dependencies required\")\n"
     ]
    }
   ],
   "source": [
    "# Import required modules\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# EFA modules\n",
    "from soc_opros_loader import SocOprosLoader\n",
    "from efa_analyzer import EFAAnalyzer, FactorSolution\n",
    "from factor_validator import FactorValidator\n",
    "from efa_error_handling import get_warning_manager, configure_warnings\n",
    "\n",
    "# Configure warnings\n",
    "configure_warnings(show_warnings=True, level=\"WARNING\")\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='efa_analyzer')\n",
    "\n",
    "print(\"‚úì Modules imported successfully\")\n",
    "print(\"‚úì EFA environment ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e701a64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:20:12.964723Z",
     "iopub.status.busy": "2025-11-24T21:20:12.963704Z",
     "iopub.status.idle": "2025-11-24T21:20:13.644278Z",
     "shell.execute_reply": "2025-11-24T21:20:13.644278Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:soc_opros_loader:Loading data from: https://docs.google.com/spreadsheets/d/17oJL-hVMqOehHFugKHDJBmGtbWkp7e1y4ccJFnxwapk/export?format=csv&gid=992488085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load soc opros data from Google Sheets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:soc_opros_loader:Data loaded successfully with encoding: utf-8 - Shape: (265, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:soc_opros_loader:Column names: ['statements', '–ê–º–µ–ª–∏—è', '–ò—Ç–∞–Ω–∏–æ', '–û—Ç–µ—Ü', '–í–∞–∞–ª', '–ü–∏–∫', '–°—Ç–∏–ª—à–µ–π–¥', '–ü–ò–ü–ò–ü–ò', '–ê–π—Å–∞', '–ö–µ–ª—å', '–ò–µ–∑–µ–∫–∏–ª—å', '–ù–µ–ª–æ—Ç', '–ò–Ω–Ω–µ–∞–¥', '–î–∂–∞–∑–∞—Ä', '–ö–∞—è', '–ê–π—à–∞']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:soc_opros_loader:Structure parsed - 265 statements, 15 respondents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:soc_opros_loader:Filling 667 missing values with neutral response (3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:soc_opros_loader:Responses matrix created - Shape: (265, 15)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Real data loaded successfully\n",
      "Data shape: (265, 15) (statements √ó respondents)\n",
      "‚úì EFA data prepared: (15, 265) (observations √ó variables)\n",
      "\n",
      "Data Overview:\n",
      "- Number of respondents (observations): 15\n",
      "- Number of statements (variables): 265\n",
      "- Missing data: 0 values (0.0%)\n",
      "- Response range: 1 to 5\n"
     ]
    }
   ],
   "source": [
    "# Load soc opros survey data\n",
    "try:\n",
    "    loader = SocOprosLoader()\n",
    "    \n",
    "    # Try to load real data first\n",
    "    print(\"Attempting to load soc opros data from Google Sheets...\")\n",
    "    data = loader.load_data()\n",
    "    responses_matrix = loader.get_responses_matrix()\n",
    "    \n",
    "    print(f\"‚úì Real data loaded successfully\")\n",
    "    print(f\"Data shape: {responses_matrix.shape} (statements √ó respondents)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not load real data: {e}\")\n",
    "    print(\"Using mock data for demonstration...\")\n",
    "    \n",
    "    # Create mock data for demonstration\n",
    "    from efa_integration_test import create_mock_soc_opros_data\n",
    "    responses_matrix = create_mock_soc_opros_data()\n",
    "    print(f\"‚úì Mock data created: {responses_matrix.shape} (statements √ó respondents)\")\n",
    "\n",
    "# For EFA, we need observations √ó variables format\n",
    "efa_data = responses_matrix.T  # Transpose to get respondents √ó statements\n",
    "print(f\"‚úì EFA data prepared: {efa_data.shape} (observations √ó variables)\")\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\nData Overview:\")\n",
    "print(f\"- Number of respondents (observations): {efa_data.shape[0]}\")\n",
    "print(f\"- Number of statements (variables): {efa_data.shape[1]}\")\n",
    "print(f\"- Missing data: {efa_data.isnull().sum().sum()} values ({(efa_data.isnull().sum().sum()/efa_data.size)*100:.1f}%)\")\n",
    "print(f\"- Response range: {efa_data.min().min():.0f} to {efa_data.max().max():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89c2d4d",
   "metadata": {},
   "source": [
    "## 2. Data Validation and Initial Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9c4a282",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:20:13.646298Z",
     "iopub.status.busy": "2025-11-24T21:20:13.646298Z",
     "iopub.status.idle": "2025-11-24T21:20:13.650506Z",
     "shell.execute_reply": "2025-11-24T21:20:13.650506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì EFA Analyzer initialized:\n",
      "  - Extraction method: principal\n",
      "  - Rotation method: oblimin\n",
      "  - Factor count: Auto-determine\n"
     ]
    }
   ],
   "source": [
    "# Initialize EFA analyzer and validator\n",
    "efa_analyzer = EFAAnalyzer(\n",
    "    n_factors=None,  # Auto-determine using eigenvalue > 1.0 criterion\n",
    "    extraction_method='principal',\n",
    "    rotation_method='oblimin'  # Default oblimin rotation\n",
    ")\n",
    "\n",
    "validator = FactorValidator()\n",
    "\n",
    "print(\"‚úì EFA Analyzer initialized:\")\n",
    "print(f\"  - Extraction method: {efa_analyzer.extraction_method}\")\n",
    "print(f\"  - Rotation method: {efa_analyzer.rotation_method}\")\n",
    "print(f\"  - Factor count: {'Auto-determine' if efa_analyzer.n_factors is None else efa_analyzer.n_factors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b519a69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:20:13.652523Z",
     "iopub.status.busy": "2025-11-24T21:20:13.651518Z",
     "iopub.status.idle": "2025-11-24T21:20:13.657406Z",
     "shell.execute_reply": "2025-11-24T21:20:13.657406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Validation Results:\n",
      "========================================\n",
      "‚úì Data validity: VALID\n",
      "\n",
      "Warnings:\n",
      "  1. More variables (265) than observations (15). Results may be unstable - consider dimensionality reduction.\n",
      "  2. Small sample: 15 observations for 265 variables. Recommended: ‚â•1325\n",
      "  3. factor_analyzer not available - install dependencies for full validation\n",
      "\n",
      "‚úì Sample adequacy: INADEQUATE\n",
      "  - Sample size: 15\n",
      "  - Variables: 265\n",
      "  - Ratio: 0.06 (recommended: ‚â•5.0)\n",
      "\n",
      "Recommendations:\n",
      "  ‚Ä¢ Increase sample size to at least 1325\n"
     ]
    }
   ],
   "source": [
    "# Perform data validation\n",
    "print(\"Data Validation Results:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Basic data validation\n",
    "validation_results = efa_analyzer.validate_data(efa_data)\n",
    "\n",
    "print(f\"‚úì Data validity: {'VALID' if validation_results.is_valid else 'INVALID'}\")\n",
    "\n",
    "if validation_results.warnings:\n",
    "    print(\"\\nWarnings:\")\n",
    "    for i, warning in enumerate(validation_results.warnings, 1):\n",
    "        print(f\"  {i}. {warning}\")\n",
    "        \n",
    "if validation_results.errors:\n",
    "    print(\"\\nErrors:\")\n",
    "    for i, error in enumerate(validation_results.errors, 1):\n",
    "        print(f\"  {i}. {error}\")\n",
    "\n",
    "# Data adequacy assessment\n",
    "adequacy_results = validator.check_data_adequacy(efa_data)\n",
    "\n",
    "print(f\"\\n‚úì Sample adequacy: {'ADEQUATE' if adequacy_results.is_adequate else 'INADEQUATE'}\")\n",
    "print(f\"  - Sample size: {adequacy_results.sample_size}\")\n",
    "print(f\"  - Variables: {adequacy_results.n_variables}\")\n",
    "print(f\"  - Ratio: {adequacy_results.ratio:.2f} (recommended: ‚â•5.0)\")\n",
    "\n",
    "if adequacy_results.recommendations:\n",
    "    print(\"\\nRecommendations:\")\n",
    "    for rec in adequacy_results.recommendations:\n",
    "        print(f\"  ‚Ä¢ {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b52ad3",
   "metadata": {},
   "source": [
    "## 2.1. Statistical Validation Tests\n",
    "\n",
    "### KMO (Kaiser-Meyer-Olkin) Test\n",
    "Measures sampling adequacy - should be ‚â• 0.6 for factor analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ca57f04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:20:13.658408Z",
     "iopub.status.busy": "2025-11-24T21:20:13.658408Z",
     "iopub.status.idle": "2025-11-24T21:20:13.773819Z",
     "shell.execute_reply": "2025-11-24T21:20:13.773819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMO Measure of Sampling Adequacy:\n",
      "========================================\n",
      "Overall KMO: nan\n",
      "Interpretation: Unacceptable - factor analysis not recommended\n",
      "Threshold: ‚â• 0.6\n",
      "Test result: ‚úó FAIL\n",
      "\n",
      "Variables with low KMO (< 0.5):\n",
      "  Life should have an end: 0.000\n",
      "  You should do whatever you want regardless of consequences: 0.000\n",
      "  It is good to be alive: 0.000\n",
      "  Existing is good: 0.000\n",
      "  You consider yourself happy: 0.000\n",
      "\n",
      "Recommendations:\n",
      "  ‚Ä¢ Consider removing variables with low individual KMO: Life should have an end, You should do whatever you want regardless of consequences, It is good to be alive, Existing is good, You consider yourself happy\n",
      "  ‚Ä¢ Variables with very low KMO (< 0.3) should be removed: Life should have an end, You should do whatever you want regardless of consequences, It is good to be alive\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\Insight Digger\\notebooks\\../src\\factor_validator.py:256: RuntimeWarning: invalid value encountered in sqrt\n",
      "  partial_corr[i, j] = -corr_inv[i, j] / np.sqrt(corr_inv[i, i] * corr_inv[j, j])\n"
     ]
    }
   ],
   "source": [
    "# KMO (Kaiser-Meyer-Olkin) Test\n",
    "print(\"KMO Measure of Sampling Adequacy:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    kmo_results = validator.calculate_kmo(efa_data)\n",
    "    \n",
    "    print(f\"Overall KMO: {kmo_results['overall_kmo']:.3f}\")\n",
    "    print(f\"Interpretation: {kmo_results['interpretation']}\")\n",
    "    print(f\"Threshold: ‚â• {kmo_results['threshold']}\")\n",
    "    print(f\"Test result: {'‚úì PASS' if kmo_results['is_adequate'] else '‚úó FAIL'}\")\n",
    "    \n",
    "    # Show problematic variables\n",
    "    individual_kmo = kmo_results['individual_kmo']\n",
    "    low_kmo_vars = {var: kmo for var, kmo in individual_kmo.items() if kmo < 0.5}\n",
    "    \n",
    "    if low_kmo_vars:\n",
    "        print(f\"\\nVariables with low KMO (< 0.5):\")\n",
    "        for var, kmo in sorted(low_kmo_vars.items(), key=lambda x: x[1])[:5]:\n",
    "            print(f\"  {var}: {kmo:.3f}\")\n",
    "    else:\n",
    "        print(f\"\\n‚úì All variables have adequate individual KMO values\")\n",
    "    \n",
    "    if kmo_results['recommendations']:\n",
    "        print(f\"\\nRecommendations:\")\n",
    "        for rec in kmo_results['recommendations'][:3]:\n",
    "            print(f\"  ‚Ä¢ {rec}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"KMO calculation failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a6edd8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:20:13.775861Z",
     "iopub.status.busy": "2025-11-24T21:20:13.774830Z",
     "iopub.status.idle": "2025-11-24T21:20:13.783906Z",
     "shell.execute_reply": "2025-11-24T21:20:13.783906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bartlett's Test of Sphericity:\n",
      "========================================\n",
      "Chi-square statistic: -inf\n",
      "Degrees of freedom: 34980\n",
      "P-value: 0.500000\n",
      "Significance level: Œ± = 0.05\n",
      "Test result: ‚úó FAIL\n",
      "Interpretation: Not significant - correlation matrix may not differ from identity matrix (poor for factor analysis)\n",
      "\n",
      "Recommendations:\n",
      "  ‚Ä¢ Factor analysis may not be appropriate - variables appear uncorrelated\n",
      "  ‚Ä¢ Consider checking data quality and variable selection\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\Insight Digger\\notebooks\\../src\\factor_validator.py:393: RuntimeWarning: divide by zero encountered in log\n",
      "  chi_square = -(n_obs - 1 - (2 * n_vars + 5) / 6) * np.log(det_corr)\n"
     ]
    }
   ],
   "source": [
    "# Bartlett's Test of Sphericity\n",
    "print(\"Bartlett's Test of Sphericity:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    bartlett_results = validator.calculate_bartlett_test(efa_data)\n",
    "    \n",
    "    print(f\"Chi-square statistic: {bartlett_results['statistic']:.3f}\")\n",
    "    print(f\"Degrees of freedom: {bartlett_results['degrees_of_freedom']}\")\n",
    "    print(f\"P-value: {bartlett_results['p_value']:.6f}\")\n",
    "    print(f\"Significance level: Œ± = {bartlett_results['alpha']}\")\n",
    "    print(f\"Test result: {'‚úì PASS' if bartlett_results['is_significant'] else '‚úó FAIL'}\")\n",
    "    print(f\"Interpretation: {bartlett_results['interpretation']}\")\n",
    "    \n",
    "    if bartlett_results['recommendations']:\n",
    "        print(f\"\\nRecommendations:\")\n",
    "        for rec in bartlett_results['recommendations'][:2]:\n",
    "            print(f\"  ‚Ä¢ {rec}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Bartlett's test failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46dd0c16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:20:13.785297Z",
     "iopub.status.busy": "2025-11-24T21:20:13.785297Z",
     "iopub.status.idle": "2025-11-24T21:20:13.789830Z",
     "shell.execute_reply": "2025-11-24T21:20:13.789324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced Sample Size Assessment:\n",
      "========================================\n",
      "Overall Assessment: Inadequate\n",
      "Sample Size: 15 observations\n",
      "Variables: 265\n",
      "Ratio: 0.1:1 (obs:vars)\n",
      "\n",
      "Detailed Assessment:\n",
      "  ‚Ä¢ Comrey & Lee (1992): Unacceptable\n",
      "  ‚Ä¢ Obs:Var ratio (0.1:1): Inadequate\n",
      "  ‚Ä¢ Factor stability: Very Low\n",
      "\n",
      "Recommendations:\n",
      "  ‚Ä¢ Critical: Sample size below minimum threshold - analysis not recommended\n",
      "  ‚Ä¢ Critical: Too few observations per variable - increase sample size\n",
      "  ‚Ä¢ Target sample size: 3975 observations for stable results\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Sample Size Assessment\n",
    "print(\"Enhanced Sample Size Assessment:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    adequacy_results = validator.check_enhanced_sample_adequacy(efa_data)\n",
    "    \n",
    "    print(f\"Overall Assessment: {adequacy_results['overall_adequacy']}\")\n",
    "    print(f\"Sample Size: {adequacy_results['sample_size']} observations\")\n",
    "    print(f\"Variables: {adequacy_results['n_variables']}\")\n",
    "    print(f\"Ratio: {adequacy_results['ratio']:.1f}:1 (obs:vars)\")\n",
    "    \n",
    "    print(f\"\\nDetailed Assessment:\")\n",
    "    for assessment in adequacy_results['assessments']:\n",
    "        print(f\"  ‚Ä¢ {assessment}\")\n",
    "    \n",
    "    if adequacy_results['recommendations']:\n",
    "        print(f\"\\nRecommendations:\")\n",
    "        for rec in adequacy_results['recommendations'][:3]:\n",
    "            print(f\"  ‚Ä¢ {rec}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Sample adequacy check failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bf7f36d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:20:13.790843Z",
     "iopub.status.busy": "2025-11-24T21:20:13.790843Z",
     "iopub.status.idle": "2025-11-24T21:20:13.799668Z",
     "shell.execute_reply": "2025-11-24T21:20:13.799668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix Quality Assessment:\n",
      "========================================\n",
      "Correlation matrix check failed: Correlation matrix is singular (determinant=-0.00e+00). Remove perfectly correlated or constant variables.\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Correlation Matrix Quality Check\n",
    "print(\"Correlation Matrix Quality Assessment:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    correlation_matrix = efa_analyzer.calculate_correlation_matrix(efa_data, method='pearson')\n",
    "    singularity_results = validator.check_correlation_singularity(correlation_matrix)\n",
    "    \n",
    "    print(f\"Matrix Condition: {singularity_results['severity']}\")\n",
    "    print(f\"Determinant: {singularity_results['determinant']:.2e}\")\n",
    "    print(f\"Condition Number: {singularity_results['condition_number']:.2e}\")\n",
    "    \n",
    "    print(f\"Singular: {'Yes' if singularity_results['is_singular'] else 'No'}\")\n",
    "    print(f\"Near-singular: {'Yes' if singularity_results['is_near_singular'] else 'No'}\")\n",
    "    \n",
    "    if singularity_results['perfect_correlations']:\n",
    "        print(f\"\\nPerfect correlations found ({len(singularity_results['perfect_correlations'])}):\")\n",
    "        for var1, var2, corr in singularity_results['perfect_correlations'][:3]:\n",
    "            print(f\"  ‚Ä¢ {var1} ‚Üî {var2}: r = {corr:.3f}\")\n",
    "    \n",
    "    if singularity_results['high_correlations']:\n",
    "        print(f\"\\nHigh correlations found ({len(singularity_results['high_correlations'])}):\")\n",
    "        for var1, var2, corr in singularity_results['high_correlations'][:3]:\n",
    "            print(f\"  ‚Ä¢ {var1} ‚Üî {var2}: r = {corr:.3f}\")\n",
    "    \n",
    "    print(f\"\\nInterpretation: {singularity_results['interpretation']}\")\n",
    "    \n",
    "    if singularity_results['recommendations']:\n",
    "        print(f\"Recommendations:\")\n",
    "        for rec in singularity_results['recommendations'][:3]:\n",
    "            print(f\"  ‚Ä¢ {rec}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Correlation matrix check failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03108299",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:20:13.800685Z",
     "iopub.status.busy": "2025-11-24T21:20:13.800685Z",
     "iopub.status.idle": "2025-11-24T21:20:13.805187Z",
     "shell.execute_reply": "2025-11-24T21:20:13.805187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATISTICAL VALIDATION SUMMARY:\n",
      "==================================================\n",
      "Could not generate validation summary - check individual test results above\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Validation Summary\n",
    "print(\"STATISTICAL VALIDATION SUMMARY:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "validation_passed = 0\n",
    "total_tests = 4\n",
    "\n",
    "# Collect all validation results\n",
    "try:\n",
    "    kmo_pass = kmo_results['is_adequate']\n",
    "    bartlett_pass = bartlett_results['is_significant'] \n",
    "    adequacy_pass = adequacy_results['overall_adequacy'] in ['Adequate', 'Good', 'Excellent']\n",
    "    matrix_pass = not (singularity_results['is_singular'] or singularity_results['is_near_singular'])\n",
    "    \n",
    "    print(f\"1. KMO Test: {'‚úì PASS' if kmo_pass else '‚úó FAIL'} (KMO = {kmo_results['overall_kmo']:.3f})\")\n",
    "    print(f\"2. Bartlett's Test: {'‚úì PASS' if bartlett_pass else '‚úó FAIL'} (p = {bartlett_results['p_value']:.4f})\")\n",
    "    print(f\"3. Sample Adequacy: {'‚úì PASS' if adequacy_pass else '‚úó FAIL'} ({adequacy_results['overall_adequacy']})\")\n",
    "    print(f\"4. Matrix Quality: {'‚úì PASS' if matrix_pass else '‚úó FAIL'} ({singularity_results['severity']})\")\n",
    "    \n",
    "    validation_passed = sum([kmo_pass, bartlett_pass, adequacy_pass, matrix_pass])\n",
    "    \n",
    "    print(f\"\\nOverall Validation: {validation_passed}/{total_tests} tests passed\")\n",
    "    \n",
    "    if validation_passed >= 3:\n",
    "        print(\"üéØ VALIDATION RESULT: GOOD - Factor analysis can proceed\")\n",
    "        proceed_recommendation = \"Proceed with factor analysis\"\n",
    "    elif validation_passed >= 2:\n",
    "        print(\"‚ö†Ô∏è  VALIDATION RESULT: MARGINAL - Proceed with caution\")\n",
    "        proceed_recommendation = \"Factor analysis possible but interpret results carefully\"\n",
    "    else:\n",
    "        print(\"‚ùå VALIDATION RESULT: POOR - Factor analysis not recommended\")\n",
    "        proceed_recommendation = \"Improve data quality before proceeding\"\n",
    "    \n",
    "    print(f\"Recommendation: {proceed_recommendation}\")\n",
    "    \n",
    "except:\n",
    "    print(\"Could not generate validation summary - check individual test results above\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a93c07",
   "metadata": {},
   "source": [
    "## 3. Correlation Matrix Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47824460",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:20:13.806202Z",
     "iopub.status.busy": "2025-11-24T21:20:13.806202Z",
     "iopub.status.idle": "2025-11-24T21:20:14.254374Z",
     "shell.execute_reply": "2025-11-24T21:20:14.254374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Correlation Matrix:\n",
      "========================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Correlation matrix is singular (determinant=-0.00e+00). Remove perfectly correlated or constant variables.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCalculating Correlation Matrix:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m40\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m correlation_matrix = \u001b[43mefa_analyzer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcalculate_correlation_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mefa_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpearson\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úì Correlation matrix calculated: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrelation_matrix.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (variables √ó variables)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  - Method: Pearson correlations with pairwise deletion\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\workspace\\Insight Digger\\notebooks\\../src\\efa_analyzer.py:350\u001b[39m, in \u001b[36mEFAAnalyzer.calculate_correlation_matrix\u001b[39m\u001b[34m(self, data, method, chunk_size)\u001b[39m\n\u001b[32m    348\u001b[39m det = np.linalg.det(corr_matrix.values)\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(det) < \u001b[32m1e-8\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCorrelation matrix is singular (determinant=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdet\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m). \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    351\u001b[39m                    \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRemove perfectly correlated or constant variables.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# Condition number check\u001b[39;00m\n\u001b[32m    354\u001b[39m cond_num = np.linalg.cond(corr_matrix.values)\n",
      "\u001b[31mValueError\u001b[39m: Correlation matrix is singular (determinant=-0.00e+00). Remove perfectly correlated or constant variables."
     ]
    }
   ],
   "source": [
    "# Calculate correlation matrix using Pearson correlations\n",
    "print(\"Calculating Correlation Matrix:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "correlation_matrix = efa_analyzer.calculate_correlation_matrix(efa_data, method=\"pearson\")\n",
    "\n",
    "print(f\"‚úì Correlation matrix calculated: {correlation_matrix.shape} (variables √ó variables)\")\n",
    "print(f\"  - Method: Pearson correlations with pairwise deletion\")\n",
    "print(f\"  - Range: {correlation_matrix.min().min():.3f} to {correlation_matrix.max().max():.3f}\")\n",
    "\n",
    "# Display correlation matrix summary\n",
    "print(\"\\nCorrelation Matrix Summary:\")\n",
    "mask = ~np.eye(correlation_matrix.shape[0], dtype=bool)  # Exclude diagonal\n",
    "off_diag_corrs = correlation_matrix.values[mask]\n",
    "\n",
    "print(f\"  - Mean absolute correlation: {np.abs(off_diag_corrs).mean():.3f}\")\n",
    "print(f\"  - Max absolute correlation: {np.abs(off_diag_corrs).max():.3f}\")\n",
    "print(f\"  - Correlations > 0.3: {(np.abs(off_diag_corrs) > 0.3).sum()} ({(np.abs(off_diag_corrs) > 0.3).mean()*100:.1f}%)\")\n",
    "print(f\"  - Correlations > 0.7: {(np.abs(off_diag_corrs) > 0.7).sum()} ({(np.abs(off_diag_corrs) > 0.7).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa222c4",
   "metadata": {},
   "source": [
    "## 4. Factor Analysis Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e712ba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:20:14.256457Z",
     "iopub.status.busy": "2025-11-24T21:20:14.256457Z",
     "iopub.status.idle": "2025-11-24T21:20:14.265166Z",
     "shell.execute_reply": "2025-11-24T21:20:14.265166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Factor Analysis:\n",
      "========================================\n",
      "‚ùå Factor analysis failed: Correlation matrix is singular (determinant=-0.00e+00). Remove perfectly correlated or constant variables.\n"
     ]
    }
   ],
   "source": [
    "# Perform complete factor analysis\n",
    "print(\"Performing Factor Analysis:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    factor_solution = efa_analyzer.fit(efa_data)\n",
    "    \n",
    "    print(f\"‚úì Factor analysis completed successfully\")\n",
    "    print(f\"  - Extraction method: {factor_solution.extraction_method}\")\n",
    "    print(f\"  - Rotation method: {factor_solution.rotation_method}\")\n",
    "    print(f\"  - Number of factors extracted: {factor_solution.n_factors}\")\n",
    "    print(f\"  - Total variance explained: {factor_solution.variance_explained['total_variance_explained']*100:.1f}%\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Factor analysis failed: {str(e)}\")\n",
    "    factor_solution = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8429cfc7",
   "metadata": {},
   "source": [
    "## 5. Results Analysis and Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9050c72d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:20:14.266544Z",
     "iopub.status.busy": "2025-11-24T21:20:14.266544Z",
     "iopub.status.idle": "2025-11-24T21:20:14.271168Z",
     "shell.execute_reply": "2025-11-24T21:20:14.271168Z"
    }
   },
   "outputs": [],
   "source": [
    "if factor_solution is not None:\n",
    "    print(\"Factor Analysis Results:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Display eigenvalues and variance explained\n",
    "    print(\"\\nEigenvalues and Variance Explained:\")\n",
    "    for i, (eigenval, prop_var, cum_var) in enumerate(zip(\n",
    "        factor_solution.variance_explained['eigenvalues'],\n",
    "        factor_solution.variance_explained['proportion_variance'],\n",
    "        factor_solution.variance_explained['cumulative_variance']\n",
    "    )):\n",
    "        print(f\"  Factor {i+1}: Œª={eigenval:.3f}, Prop.Var={prop_var*100:.1f}%, Cum.Var={cum_var*100:.1f}%\")\n",
    "    \n",
    "    # Display factor loadings\n",
    "    print(\"\\nFactor Loadings Matrix (first 10 variables):\")\n",
    "    display_loadings = factor_solution.loadings.head(10).round(3)\n",
    "    print(display_loadings.to_string())\n",
    "    \n",
    "    # Highlight significant loadings (>0.4)\n",
    "    print(\"\\nSignificant Factor Loadings (|loading| > 0.4):\")\n",
    "    for factor in factor_solution.loadings.columns:\n",
    "        significant = factor_solution.loadings[factor][np.abs(factor_solution.loadings[factor]) > 0.4]\n",
    "        if len(significant) > 0:\n",
    "            print(f\"\\n{factor}:\")\n",
    "            for var, loading in significant.sort_values(key=abs, ascending=False).items():\n",
    "                print(f\"  {var}: {loading:.3f}\")\n",
    "        else:\n",
    "            print(f\"\\n{factor}: No significant loadings found\")\n",
    "    \n",
    "    # Display communalities\n",
    "    print(\"\\nCommunalities (first 10 variables):\")\n",
    "    display_communalities = factor_solution.communalities.head(10).round(3)\n",
    "    for var, comm in display_communalities.items():\n",
    "        print(f\"  {var}: {comm:.3f}\")\n",
    "    \n",
    "    print(f\"\\nCommunalities Summary:\")\n",
    "    print(f\"  - Mean: {factor_solution.communalities.mean():.3f}\")\n",
    "    print(f\"  - Range: {factor_solution.communalities.min():.3f} to {factor_solution.communalities.max():.3f}\")\n",
    "    print(f\"  - Variables with comm. > 0.5: {(factor_solution.communalities > 0.5).sum()}/{len(factor_solution.communalities)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc24ac2b",
   "metadata": {},
   "source": [
    "## 6. Factor Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d902c40b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:20:14.273187Z",
     "iopub.status.busy": "2025-11-24T21:20:14.272181Z",
     "iopub.status.idle": "2025-11-24T21:20:14.276612Z",
     "shell.execute_reply": "2025-11-24T21:20:14.276612Z"
    }
   },
   "outputs": [],
   "source": [
    "if factor_solution is not None:\n",
    "    print(\"Factor Interpretation:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    try:\n",
    "        interpretation = efa_analyzer.get_factor_interpretation(factor_solution, loading_threshold=0.4)\n",
    "        \n",
    "        # Overall structure quality\n",
    "        structure = interpretation['structure_summary']\n",
    "        print(f\"Simple Structure Quality: {structure['simple_structure_quality']}\")\n",
    "        print(f\"Variables assigned to factors: {structure['assigned_variables']}/{structure['total_variables']}\")\n",
    "        print(f\"Unassigned variables: {structure['unassigned_variables']}\")\n",
    "        \n",
    "        # Factor-by-factor interpretation\n",
    "        for factor_name, factor_info in interpretation['factor_interpretations'].items():\n",
    "            print(f\"\\n{factor_name}:\")\n",
    "            print(f\"  - Interpretation quality: {factor_info['interpretation_quality']}\")\n",
    "            print(f\"  - Variables with significant loadings: {factor_info['n_significant']}\")\n",
    "            print(f\"  - Maximum loading: {factor_info['max_loading']:.3f}\")\n",
    "            \n",
    "            if factor_info['high_loading_variables']:\n",
    "                print(\"  - High loading variables:\")\n",
    "                for var, loading in list(factor_info['high_loading_variables'].items())[:5]:  # Top 5\n",
    "                    print(f\"    ‚Ä¢ {var}: {loading:.3f}\")\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"Could not generate interpretation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a778170",
   "metadata": {},
   "source": [
    "## 7. Factor Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "943c275b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:20:14.278630Z",
     "iopub.status.busy": "2025-11-24T21:20:14.277625Z",
     "iopub.status.idle": "2025-11-24T21:20:14.281639Z",
     "shell.execute_reply": "2025-11-24T21:20:14.281639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factor scores not available\n"
     ]
    }
   ],
   "source": [
    "if factor_solution is not None and factor_solution.factor_scores is not None:\n",
    "    print(\"Factor Scores Summary:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    scores = factor_solution.factor_scores\n",
    "    \n",
    "    print(f\"Factor scores calculated for {len(scores)} observations\")\n",
    "    print(f\"Method: Regression method (precise estimation)\")\n",
    "    \n",
    "    print(\"\\nFactor Score Statistics:\")\n",
    "    for factor in scores.columns:\n",
    "        mean_score = scores[factor].mean()\n",
    "        std_score = scores[factor].std()\n",
    "        print(f\"  {factor}: M={mean_score:.3f}, SD={std_score:.3f}\")\n",
    "    \n",
    "    # Display first few factor scores\n",
    "    print(\"\\nFirst 5 Respondents' Factor Scores:\")\n",
    "    print(scores.head().round(3).to_string())\n",
    "    \n",
    "    # Factor score correlations (should be low for oblique rotation)\n",
    "    print(\"\\nFactor Score Correlations:\")\n",
    "    factor_corrs = scores.corr().round(3)\n",
    "    print(factor_corrs.to_string())\n",
    "else:\n",
    "    print(\"Factor scores not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a8234a",
   "metadata": {},
   "source": [
    "## 8. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9efc989",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:20:14.282655Z",
     "iopub.status.busy": "2025-11-24T21:20:14.282655Z",
     "iopub.status.idle": "2025-11-24T21:20:14.288208Z",
     "shell.execute_reply": "2025-11-24T21:20:14.288208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic EFA Analysis Summary:\n",
      "==================================================\n",
      "‚ùå Factor analysis failed - check data quality and dependencies\n",
      "\n",
      "Next Steps:\n",
      "1. Install scipy and factor-analyzer for full functionality\n",
      "2. Run statistical validation (User Story 2)\n",
      "3. Create visualizations (User Story 3)\n",
      "4. Apply to real soc opros survey data\n"
     ]
    }
   ],
   "source": [
    "print(\"Basic EFA Analysis Summary:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if factor_solution is not None:\n",
    "    success_criteria = {\n",
    "        'factors_extracted': factor_solution.n_factors,\n",
    "        'variance_explained': factor_solution.variance_explained['total_variance_explained'] * 100,\n",
    "        'target_variance': 60.0,  # From success criteria SC-001\n",
    "        'target_factors': (3, 8),  # From success criteria SC-001\n",
    "        'factor_range_ok': 3 <= factor_solution.n_factors <= 8,\n",
    "        'variance_ok': factor_solution.variance_explained['total_variance_explained'] >= 0.60\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úì Number of factors: {success_criteria['factors_extracted']} (target: {success_criteria['target_factors'][0]}-{success_criteria['target_factors'][1]})\")\n",
    "    print(f\"‚úì Variance explained: {success_criteria['variance_explained']:.1f}% (target: ‚â•{success_criteria['target_variance']}%)\")\n",
    "    print(f\"‚úì Factor count within range: {'YES' if success_criteria['factor_range_ok'] else 'NO'}\")\n",
    "    print(f\"‚úì Variance target met: {'YES' if success_criteria['variance_ok'] else 'NO'}\")\n",
    "    \n",
    "    overall_success = success_criteria['factor_range_ok'] and success_criteria['variance_ok']\n",
    "    print(f\"\\nüéØ MVP Success Criteria: {'PASSED ‚úì' if overall_success else 'PARTIAL ‚ö†Ô∏è'}\")\n",
    "    \n",
    "    if overall_success:\n",
    "        print(\"\\nüéâ Basic Factor Discovery (US1) completed successfully!\")\n",
    "        print(\"Ready to proceed to User Story 2: Statistical Validation\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Some success criteria not met - review data quality and sample size\")\n",
    "else:\n",
    "    print(\"‚ùå Factor analysis failed - check data quality and dependencies\")\n",
    "\n",
    "# Show any accumulated warnings\n",
    "warning_mgr = get_warning_manager()\n",
    "summary = warning_mgr.get_summary()\n",
    "if summary['total'] > 0:\n",
    "    print(f\"\\nWarnings generated: {summary['total']}\")\n",
    "    print(f\"By level: {summary['by_level']}\")\n",
    "\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"1. Install scipy and factor-analyzer for full functionality\")\n",
    "print(\"2. Run statistical validation (User Story 2)\")\n",
    "print(\"3. Create visualizations (User Story 3)\")\n",
    "print(\"4. Apply to real soc opros survey data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Insight Digger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
